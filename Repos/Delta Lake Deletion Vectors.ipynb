{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c53f22e3-babe-4852-8c08-eb5cb7e3becd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Delta Deletion Vector Demo - Focus on MERGE Operations\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Configuration\n",
    "catalog = \"youssef_demos\"\n",
    "schema = \"test\"\n",
    "\n",
    "print(\"üöÄ Delta Deletion Vector Demo\")\n",
    "print(\"Focus: How deletion vectors improve MERGE performance\")\n",
    "print(\"\\nüìö Key Points:\")\n",
    "print(\"‚Ä¢ Deletion vectors track deleted rows without rewriting files\")\n",
    "print(\"‚Ä¢ Especially beneficial for MERGE operations (UPDATE/DELETE)\")\n",
    "print(\"‚Ä¢ Trade-off: Faster writes, slightly slower reads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c65094b-6a0e-4777-82c8-ea55946ff582",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Generate Sample Orders Dataset"
    }
   },
   "outputs": [],
   "source": [
    "# Create sample orders data for MERGE demo with more realistic columns\n",
    "print(\"üìä Creating sample data...\")\n",
    "\n",
    "# Generate 2M orders with more columns for realistic MERGE demo\n",
    "orders_df = spark.range(2000000).select(\n",
    "    col(\"id\").alias(\"order_id\"),\n",
    "    (rand() * 10000 + 1).cast(\"int\").alias(\"customer_id\"),\n",
    "    (rand() * 500 + 10).cast(\"decimal(10,2)\").alias(\"amount\"),\n",
    "    (rand() * 50 + 1).cast(\"decimal(8,2)\").alias(\"tax_amount\"),\n",
    "    (rand() * 20 + 5).cast(\"decimal(8,2)\").alias(\"shipping_cost\"),\n",
    "    when(rand() < 0.8, \"active\").otherwise(\"cancelled\").alias(\"status\"),\n",
    "    when(rand() < 0.3, \"online\")\n",
    "    .when(rand() < 0.7, \"store\")\n",
    "    .otherwise(\"mobile\").alias(\"channel\"),\n",
    "    when(rand() < 0.4, \"credit_card\")\n",
    "    .when(rand() < 0.7, \"debit_card\")\n",
    "    .when(rand() < 0.9, \"paypal\")\n",
    "    .otherwise(\"bank_transfer\").alias(\"payment_method\"),\n",
    "    (rand() * 100 + 1).cast(\"int\").alias(\"product_id\"),\n",
    "    (rand() * 10 + 1).cast(\"int\").alias(\"quantity\"),\n",
    "    when(rand() < 0.6, \"standard\")\n",
    "    .when(rand() < 0.9, \"express\")\n",
    "    .otherwise(\"overnight\").alias(\"shipping_method\"),\n",
    "    concat(lit(\"Order for customer \"), col(\"id\").cast(\"string\")).alias(\"order_notes\"),\n",
    "    when(rand() < 0.8, \"USD\")\n",
    "    .when(rand() < 0.95, \"EUR\")\n",
    "    .otherwise(\"GBP\").alias(\"currency\"),\n",
    "    (rand() * 5 + 1).cast(\"decimal(3,2)\").alias(\"discount_rate\"),\n",
    "    current_timestamp().alias(\"created_at\"),\n",
    "    current_timestamp().alias(\"updated_at\")\n",
    ")\n",
    "\n",
    "print(f\"Generated {orders_df.count():,} orders with {len(orders_df.columns)} columns\")\n",
    "print(\"Sample data:\")\n",
    "orders_df.show(3, truncate=False)\n",
    "print(f\"\\nColumns: {', '.join(orders_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b347e63e-5478-48b5-9c96-a51a36411642",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Table Without Deletion Vectors"
    }
   },
   "outputs": [],
   "source": [
    "# Create two identical tables - one with DV, one without\n",
    "timestamp = str(int(time.time()))\n",
    "table_with_dv = f\"{catalog}.{schema}.orders_with_dv_{timestamp}\"\n",
    "table_without_dv = f\"{catalog}.{schema}.orders_without_dv_{timestamp}\"\n",
    "\n",
    "print(f\"üìã Creating comparison tables...\")\n",
    "\n",
    "# Table WITHOUT deletion vectors\n",
    "orders_df.write.format(\"delta\") \\\n",
    "    .option(\"delta.enableDeletionVectors\", \"false\") \\\n",
    "    .saveAsTable(table_without_dv)\n",
    "\n",
    "# Table WITH deletion vectors (default)\n",
    "orders_df.write.format(\"delta\").saveAsTable(table_with_dv)\n",
    "\n",
    "print(f\"‚úÖ Created tables:\")\n",
    "print(f\"Without DV: {table_without_dv}\")\n",
    "print(f\"With DV: {table_with_dv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e8ecb06-aaeb-44e8-a7b0-a1b02ead24d8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Table With Deletion Vectors"
    }
   },
   "outputs": [],
   "source": [
    "# Create updates data for MERGE operations with more comprehensive changes\n",
    "print(\"üîÑ Preparing MERGE demo...\")\n",
    "\n",
    "# Create updates: change multiple columns for 200K orders (10% of base table)\n",
    "updates_df = spark.range(200000).select(\n",
    "    col(\"id\").alias(\"order_id\"),\n",
    "    lit(\"updated\").alias(\"new_status\"),\n",
    "    (rand() * 100 + 500).cast(\"decimal(10,2)\").alias(\"new_amount\"),\n",
    "    (rand() * 10 + 5).cast(\"decimal(8,2)\").alias(\"new_tax_amount\"),\n",
    "    (rand() * 15 + 10).cast(\"decimal(8,2)\").alias(\"new_shipping_cost\"),\n",
    "    when(rand() < 0.5, \"express\").otherwise(\"overnight\").alias(\"new_shipping_method\"),\n",
    "    (rand() * 3 + 2).cast(\"decimal(3,2)\").alias(\"new_discount_rate\"),\n",
    "    concat(lit(\"Updated order \"), col(\"id\").cast(\"string\")).alias(\"new_order_notes\"),\n",
    "    current_timestamp().alias(\"updated_at\")\n",
    ")\n",
    "\n",
    "print(f\"Created {updates_df.count():,} updates for MERGE\")\n",
    "updates_df.show(3, truncate=False)\n",
    "\n",
    "# Create new orders to insert (100K new records) with all columns\n",
    "new_orders_df = spark.range(2000000, 2100000).select(\n",
    "    col(\"id\").alias(\"order_id\"),\n",
    "    (rand() * 10000 + 1).cast(\"int\").alias(\"customer_id\"),\n",
    "    (rand() * 500 + 10).cast(\"decimal(10,2)\").alias(\"amount\"),\n",
    "    (rand() * 50 + 1).cast(\"decimal(8,2)\").alias(\"tax_amount\"),\n",
    "    (rand() * 20 + 5).cast(\"decimal(8,2)\").alias(\"shipping_cost\"),\n",
    "    lit(\"new\").alias(\"status\"),\n",
    "    lit(\"online\").alias(\"channel\"),\n",
    "    lit(\"credit_card\").alias(\"payment_method\"),\n",
    "    (rand() * 100 + 1).cast(\"int\").alias(\"product_id\"),\n",
    "    (rand() * 5 + 1).cast(\"int\").alias(\"quantity\"),\n",
    "    lit(\"standard\").alias(\"shipping_method\"),\n",
    "    concat(lit(\"New order \"), col(\"id\").cast(\"string\")).alias(\"order_notes\"),\n",
    "    lit(\"USD\").alias(\"currency\"),\n",
    "    (rand() * 2 + 1).cast(\"decimal(3,2)\").alias(\"discount_rate\"),\n",
    "    current_timestamp().alias(\"created_at\"),\n",
    "    current_timestamp().alias(\"updated_at\")\n",
    ")\n",
    "\n",
    "print(f\"Created {new_orders_df.count():,} new orders for INSERT\")\n",
    "print(f\"Total MERGE operations will be: {updates_df.count() + new_orders_df.count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c89ea91-d2b0-4583-aee0-9db3a7a4c76c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Delete Operations Comparison"
    }
   },
   "outputs": [],
   "source": [
    "# MERGE performance comparison with comprehensive column updates\n",
    "print(\"‚è±Ô∏è MERGE Performance Test\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Combine updates and new records for MERGE with matching schemas\n",
    "merge_data = updates_df.select(\n",
    "    col(\"order_id\"),\n",
    "    lit(1000).alias(\"customer_id\"),\n",
    "    col(\"new_amount\").alias(\"amount\"),\n",
    "    col(\"new_tax_amount\").alias(\"tax_amount\"),\n",
    "    col(\"new_shipping_cost\").alias(\"shipping_cost\"),\n",
    "    col(\"new_status\").alias(\"status\"),\n",
    "    lit(\"online\").alias(\"channel\"),\n",
    "    lit(\"credit_card\").alias(\"payment_method\"),\n",
    "    lit(50).alias(\"product_id\"),\n",
    "    lit(2).alias(\"quantity\"),\n",
    "    col(\"new_shipping_method\").alias(\"shipping_method\"),\n",
    "    col(\"new_order_notes\").alias(\"order_notes\"),\n",
    "    lit(\"USD\").alias(\"currency\"),\n",
    "    col(\"new_discount_rate\").alias(\"discount_rate\"),\n",
    "    col(\"updated_at\").alias(\"created_at\"),\n",
    "    col(\"updated_at\")\n",
    ").union(\n",
    "    new_orders_df.select(\n",
    "        col(\"order_id\"),\n",
    "        col(\"customer_id\"),\n",
    "        col(\"amount\"),\n",
    "        col(\"tax_amount\"),\n",
    "        col(\"shipping_cost\"),\n",
    "        col(\"status\"),\n",
    "        col(\"channel\"),\n",
    "        col(\"payment_method\"),\n",
    "        col(\"product_id\"),\n",
    "        col(\"quantity\"),\n",
    "        col(\"shipping_method\"),\n",
    "        col(\"order_notes\"),\n",
    "        col(\"currency\"),\n",
    "        col(\"discount_rate\"),\n",
    "        col(\"created_at\"),\n",
    "        col(\"updated_at\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Total MERGE operations: {merge_data.count():,}\")\n",
    "\n",
    "# MERGE into table WITHOUT deletion vectors\n",
    "print(\"\\nüö´ MERGE without deletion vectors...\")\n",
    "start_time = time.time()\n",
    "\n",
    "DeltaTable.forName(spark, table_without_dv).alias(\"target\") \\\n",
    "    .merge(merge_data.alias(\"source\"), \"target.order_id = source.order_id\") \\\n",
    "    .whenMatchedUpdate(set={\n",
    "        \"amount\": \"source.amount\",\n",
    "        \"tax_amount\": \"source.tax_amount\",\n",
    "        \"shipping_cost\": \"source.shipping_cost\",\n",
    "        \"status\": \"source.status\",\n",
    "        \"shipping_method\": \"source.shipping_method\",\n",
    "        \"order_notes\": \"source.order_notes\",\n",
    "        \"discount_rate\": \"source.discount_rate\",\n",
    "        \"updated_at\": \"source.updated_at\"\n",
    "    }) \\\n",
    "    .whenNotMatchedInsert(values={\n",
    "        \"order_id\": \"source.order_id\",\n",
    "        \"customer_id\": \"source.customer_id\",\n",
    "        \"amount\": \"source.amount\",\n",
    "        \"tax_amount\": \"source.tax_amount\",\n",
    "        \"shipping_cost\": \"source.shipping_cost\",\n",
    "        \"status\": \"source.status\",\n",
    "        \"channel\": \"source.channel\",\n",
    "        \"payment_method\": \"source.payment_method\",\n",
    "        \"product_id\": \"source.product_id\",\n",
    "        \"quantity\": \"source.quantity\",\n",
    "        \"shipping_method\": \"source.shipping_method\",\n",
    "        \"order_notes\": \"source.order_notes\",\n",
    "        \"currency\": \"source.currency\",\n",
    "        \"discount_rate\": \"source.discount_rate\",\n",
    "        \"created_at\": \"source.created_at\",\n",
    "        \"updated_at\": \"source.updated_at\"\n",
    "    }) \\\n",
    "    .execute()\n",
    "\n",
    "merge_time_without_dv = time.time() - start_time\n",
    "print(f\"Time without DV: {merge_time_without_dv:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09ed169e-b8f6-49e9-8105-82db1829c761",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Performance and Storage Analysis"
    }
   },
   "outputs": [],
   "source": [
    "# MERGE into table WITH deletion vectors\n",
    "print(\"‚úÖ MERGE with deletion vectors...\")\n",
    "start_time = time.time()\n",
    "\n",
    "DeltaTable.forName(spark, table_with_dv).alias(\"target\") \\\n",
    "    .merge(merge_data.alias(\"source\"), \"target.order_id = source.order_id\") \\\n",
    "    .whenMatchedUpdate(set={\n",
    "        \"amount\": \"source.amount\",\n",
    "        \"tax_amount\": \"source.tax_amount\",\n",
    "        \"shipping_cost\": \"source.shipping_cost\",\n",
    "        \"status\": \"source.status\",\n",
    "        \"shipping_method\": \"source.shipping_method\",\n",
    "        \"order_notes\": \"source.order_notes\",\n",
    "        \"discount_rate\": \"source.discount_rate\",\n",
    "        \"updated_at\": \"source.updated_at\"\n",
    "    }) \\\n",
    "    .whenNotMatchedInsert(values={\n",
    "        \"order_id\": \"source.order_id\",\n",
    "        \"customer_id\": \"source.customer_id\",\n",
    "        \"amount\": \"source.amount\",\n",
    "        \"tax_amount\": \"source.tax_amount\",\n",
    "        \"shipping_cost\": \"source.shipping_cost\",\n",
    "        \"status\": \"source.status\",\n",
    "        \"channel\": \"source.channel\",\n",
    "        \"payment_method\": \"source.payment_method\",\n",
    "        \"product_id\": \"source.product_id\",\n",
    "        \"quantity\": \"source.quantity\",\n",
    "        \"shipping_method\": \"source.shipping_method\",\n",
    "        \"order_notes\": \"source.order_notes\",\n",
    "        \"currency\": \"source.currency\",\n",
    "        \"discount_rate\": \"source.discount_rate\",\n",
    "        \"created_at\": \"source.created_at\",\n",
    "        \"updated_at\": \"source.updated_at\"\n",
    "    }) \\\n",
    "    .execute()\n",
    "\n",
    "merge_time_with_dv = time.time() - start_time\n",
    "print(f\"Time with DV: {merge_time_with_dv:.2f} seconds\")\n",
    "\n",
    "# Show performance improvement\n",
    "if merge_time_without_dv > merge_time_with_dv:\n",
    "    speedup = merge_time_without_dv / merge_time_with_dv\n",
    "    print(f\"\\nüöÄ Deletion vectors are {speedup:.1f}x FASTER for MERGE!\")\n",
    "else:\n",
    "    print(f\"\\nüìà Results may vary based on data size and cluster resources\")\n",
    "\n",
    "print(f\"\\nüìä Performance Summary:\")\n",
    "print(f\"Without DV: {merge_time_without_dv:.2f}s\")\n",
    "print(f\"With DV: {merge_time_with_dv:.2f}s\")\n",
    "\n",
    "# Show table sizes after MERGE\n",
    "print(f\"\\nüìã Final table sizes:\")\n",
    "print(f\"Table without DV: {spark.table(table_without_dv).count():,} records\")\n",
    "print(f\"Table with DV: {spark.table(table_with_dv).count():,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9835b9bd-d432-40f1-8604-6055240bbcad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Deletion Vector Concepts and Best Practices"
    }
   },
   "outputs": [],
   "source": [
    "# Key Takeaways: When Deletion Vectors Excel\n",
    "print(\"üèÜ Key Takeaways\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "print(\"üöÄ Deletion Vectors are BEST for:\")\n",
    "print(\"‚Ä¢ MERGE operations (UPDATE + INSERT)\")\n",
    "print(\"‚Ä¢ Frequent UPDATE/DELETE workloads\")\n",
    "print(\"‚Ä¢ CDC (Change Data Capture) pipelines\")\n",
    "print(\"‚Ä¢ Streaming upserts\")\n",
    "\n",
    "print(\"\\nüìà Why MERGE benefits most:\")\n",
    "print(\"‚Ä¢ Updates don't rewrite entire files\")\n",
    "print(\"‚Ä¢ Only creates small deletion vector files\")\n",
    "print(\"‚Ä¢ Massive time savings on large tables\")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è Configuration:\")\n",
    "print(\"-- Enable (default in DBR 13.3+)\")\n",
    "print(\"CREATE TABLE orders (...) TBLPROPERTIES ('delta.enableDeletionVectors' = 'true')\")\n",
    "print(\"\\n-- Disable for read-heavy workloads\")\n",
    "print(\"CREATE TABLE orders (...) TBLPROPERTIES ('delta.enableDeletionVectors' = 'false')\")\n",
    "\n",
    "print(f\"\\nüìã Demo tables created:\")\n",
    "print(f\"With DV: {table_with_dv}\")\n",
    "print(f\"Without DV: {table_without_dv}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8502414096066285,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Delta Lake Deletion Vectors",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
